# Changelog

## [Unreleased]
- Replaced the local JSON/localOnly persistence layer with a Postgres-backed repository stack (`pg` + SQL migrations) covering sessions, chat threads/messages, tool events, uploads, misalignments, todos, and repo bindings. Added `pnpm db:migrate` and `pnpm db:import-legacy` scripts, expanded env requirements (`DATABASE_URL`, `ELECTRIC_HTTP_URL`, `ELECTRIC_SYNC_URL`), documented the rollout in `docs/db/migration-plan.md`, and updated the README with setup instructions and the new migration/import workflow.
- Added first-class Gemini CLI session ingestion (JSON fallback parser, `GEMINI_SESSION_DIR` discovery opt-in, `.json` upload UX) plus documentation in `docs/gemini-cli-support.md`.
- Updated session export docs to clarify that Gemini-derived sessions retain tool metadata when re-exported.
- Fixed Session Intelligence “Hookify Analysis Results” layout so Hook Discovery panels clamp to the viewport, maintain sticky headers, and expose the Summary footer without clipping; refreshed scroll spec + e2e coverage.
- Ensured Hookify analysis reads the active session’s repository context instead of the shared fixture, adds repo telemetry to `/api/chatbot/analyze`, enforces repo binding before analyses, and clears cached snapshots when repos change; Hook Discovery UI now resets between sessions and labels results with the bound repo.
- Chat Dock session mode now resolves timeline references automatically: user prompts that mention event IDs (e.g., `#710`) or originate from “Add to chat” metadata fetch the corresponding session events, store structured references with each chat turn, and inject the resolved payloads into the LLM context so Session Coach can answer event-level questions without manual uploads.
- Chat Dock streaming now consumes the NDJSON tool protocol end-to-end: `useChatDockController` tracks each `tool-call`/`tool-result`, merges returned `contextEvents` into the pending assistant bubble, and exposes a live `ToolCallStreamList` that renders schema-driven timeline cards (via Tool UI) alongside status badges and JSON fallbacks; persisted messages surface the same context chips so both streaming and reload states share a single view. LM Studio models inherit the same tooling path through the OpenAI-compatible provider, so local sessions can invoke timeline tools without special handling.
- Stabilized the Playwright suite by switching to a production build + `pnpm start` web server on `127.0.0.1:4173`, aligning `baseURL`/`webServer.url`, and eliminating brittle `networkidle` waits in favor of element-gated readiness checks.
- Added canonical `data-testid` constants shared between the UI and tests (`viewer-hero-title`, `viewer-title`, `session-upload-input`, `chat-textarea`, `chat-mode-*`, `viewer-log-container`) so selectors survive future content/design updates.
- Introduced public testing APIs for seeding fixtures—`POST /api/uploads` to persist JSONL files, `POST /api/session/repo-context` to bind sessions to assets, and `POST /api/logs` to append Browser Echo entries—plus updated e2e specs to seed analyze/log flows with contract-valid payloads instead of relying on legacy fallbacks.
