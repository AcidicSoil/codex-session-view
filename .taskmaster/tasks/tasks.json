{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Establish Foundational Layer: Config, Types, and Logging",
        "description": "Create the core foundation for the AI orchestration and guardrails system. This includes centralized configuration management for AI providers, shared TypeScript domain types, and a basic observability logging utility.",
        "details": "Implement three foundational modules as specified in the PRD's Phase 0. Create `src/lib/config/ai-config.ts` to load and validate environment variables (API keys, base URLs) for AI providers. Define shared data models like `ChatMessage`, `SessionContext`, `AgentsRuleset`, and `AlignmentEvent` in `src/lib/core/types.ts`. Implement a simple logging abstraction in `src/lib/observability/logging.ts` with `logInfo` and `logError` functions for server-side use.",
        "testStrategy": "Unit test `ai-config.ts` by mocking environment variables to verify correct loading and validation logic, including error handling for missing keys. For `core-types.ts`, use compile-time type checking and simple Jest tests to ensure type guards and constructors work as expected. For `logging.ts`, unit test with a mocked console or sink to ensure messages are formatted and sent correctly without throwing errors.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement AI Provider and Model Registry",
        "description": "Create a unified registry that maps logical model IDs (e.g., 'openai:gpt-4.1', 'lmstudio:local') to concrete Vercel AI SDK provider instances and configurations.",
        "details": "In `src/lib/ai/providers.ts`, implement the `resolveModel(id: ModelId)` function. This function will parse the logical model ID string, consult the configuration loaded by `ai-config`, and instantiate the appropriate Vercel AI SDK provider. For example, for 'openai:*' it should use `createOpenAI` and for 'gemini:*' it should use `createGoogleGenerativeAI`. Support providers for OpenAI-compatible endpoints, LM Studio, Gemini CLI, and `built-in-ai`. The function should return a `ResolvedModel` object containing the AI SDK model instance and its options.",
        "testStrategy": "Unit test the `resolveModel` function with various model IDs. Mock the `ai-config` module to provide different configurations. Verify that correct provider instances are created for each ID. Test edge cases like invalid or unsupported model IDs, ensuring it gracefully falls back to a default model or throws a clear error.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Develop AGENTS.md Rules Loader and Parser",
        "description": "Implement a server-side module to locate, load, parse, and cache the contents of AGENTS.md files for a given repository session. This will provide a structured ruleset for the linter.",
        "details": "Create `src/lib/agents/agents-rules.ts`. Implement the `loadAgentsRules(repoRef)` function that reads the `AGENTS.md` file from the specified repository path on the server. The function should parse the markdown file into a structured `AgentsRuleset` object, breaking it down into sections (e.g., commands, testing) and individual rules with stable IDs. Implement a caching mechanism (e.g., in-memory LRU cache) keyed by repo/path to improve performance on subsequent lookups for the same file.",
        "testStrategy": "Unit test the parsing logic with a variety of synthetic `AGENTS.md` file contents, including well-formed files, empty files, and files with unusual formatting. Verify the path resolution logic, including the specified behavior of handling root and nested override files. Test the caching mechanism to ensure it returns cached data for repeated calls and invalidates correctly if needed.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Build Central Chat Orchestrator with Streaming",
        "description": "Implement the main server-side chat function using the Vercel AI SDK to handle streaming responses, context, and tool usage uniformly across all registered AI providers.",
        "details": "In `src/lib/ai/orchestrator.ts`, create the primary server function `streamChat(request: ChatRequest)`. This function will use the `resolveModel` function from the `ai-providers` module to get the correct model instance. It will then call the Vercel AI SDK's `streamText` function, passing the model, conversation history, and any attached context. The function should return an `AIStream` that can be directly piped to the client response. On completion, it should also handle persisting the final message and associated metadata.",
        "testStrategy": "Write integration tests that call `streamChat` with a mocked AI provider (e.g., using `createMockServer` from `ai-test-utils`). Verify that the function produces a valid streaming response. Test error handling for scenarios where the provider API returns an error. Ensure latency metadata is captured correctly upon stream completion.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Create Codex Session Context Attachment Pipeline",
        "description": "Develop a module to transform raw Codex session data into a structured, concise context blob that can be attached to AI chat requests, to be used in system prompts or other context channels.",
        "details": "Implement `src/lib/ai/context-codex-session.ts`. Create the function `buildSessionContext(session: CodexSession)` which takes the raw session data and normalizes it into a `SessionContext` object. Then, create `createContextPrompt(context: SessionContext)` which constructs a concise prompt string from the context object. This prompt should summarize the session, list key events/files, and adhere to strict token limits to avoid bloating the AI request. Implement redaction rules for sensitive information if necessary.",
        "testStrategy": "Unit test `buildSessionContext` and `createContextPrompt` with various synthetic `CodexSession` objects. Verify that the output is structured correctly and that the generated prompt text is within expected size limits. Test boundary conditions, such as very large sessions, to ensure truncation logic works as designed.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement AGENTS Alignment Linter and Remediation Service",
        "description": "Create the linter service that evaluates user and assistant messages against the AGENTS.md ruleset, classifies them as aligned/warn/block, and generates corrective remediation prompts.",
        "details": "In `src/lib/agents/agents-linter.ts`, implement `lintMessage(input: LintInput)`. This function will receive the message text and the `AgentsRuleset` from Task 3. It should first run a series of fast, deterministic checks (e.g., regex for forbidden commands, file path checks). For more ambiguous cases, it can optionally call a small, fast classification LLM. It must return a structured `AlignmentResult` object with a status and a list of violated rule IDs. Also implement `buildRemediation(result: AlignmentResult)` which generates a short, actionable prompt suggesting a compliant alternative.",
        "testStrategy": "Use snapshot testing for `buildRemediation` to ensure remediation text remains stable. Write extensive unit tests for `lintMessage` covering various deterministic rules with sample messages that should pass or fail. For the optional LLM classifier, mock its output to test the logic that consumes its classification.",
        "priority": "high",
        "dependencies": [
          1,
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Define and Persist Alignment Events",
        "description": "Establish the database schema for `AlignmentEvent` records and implement the persistence layer to create and query these events. This will be the data source for all analytics.",
        "details": "In `src/lib/agents/alignment-events.ts`, define the `AlignmentEvent` schema based on the PRD, including fields like `sessionId`, `messageId`, `actor`, `status`, `ruleId`, and `severity`. Use TanStack DB or an equivalent persistence layer. Implement `createAlignmentEvent(event)` to write a new event to the database. Implement `listAlignmentEvents(filter)` to query events with filtering (by time, repo, status, etc.) and pagination. Ensure database queries are indexed for performance, particularly on filterable columns.",
        "testStrategy": "Test the persistence layer using a test database or an in-memory alternative. Write unit tests for `createAlignmentEvent` to verify that records are created correctly. For `listAlignmentEvents`, test the filtering and pagination logic to ensure it returns the correct subsets of data. Check that DB write failures are handled gracefully and do not block the main application flow.",
        "priority": "high",
        "dependencies": [
          1,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Integrate Orchestrator and Context into Session Viewer & Chat UI",
        "description": "Refactor the existing `ChatDock` component and its parent route to use the new session-scoped context and central chat orchestrator, removing any direct AI calls.",
        "details": "Modify `src/routes/codex/session-viewer.route.tsx`. Use the TanStack Start `loader` function to fetch the `CodexSession` data and pass it to the `ai-context-codex-session` and `agents-rules` modules to generate the `SessionContext` and `AgentsRuleset` on the server. Pass this data to the route component. Refactor `src/features/chatbot/ChatDock.tsx` to remove any direct AI SDK calls. Instead, it should use the `useChat` hook from Vercel AI SDK, configured to point to a new server-side API route that calls our `streamChat` orchestrator from Task 4.",
        "testStrategy": "Perform component testing on the refactored `ChatDock` using a mocked orchestrator client to verify that UI state, message streaming, and user input are handled correctly. Write an integration test for the `session-viewer.route.tsx` to ensure the loader fetches and provides all necessary context data server-side without any client-side `useEffect` fetches for this data.",
        "priority": "high",
        "dependencies": [
          4,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Non-Blocking Inline Guardrails and UI Notifications",
        "description": "Integrate the AGENTS linter into the chat flow in a non-blocking manner and display alignment warnings or suggestions to the user in the UI.",
        "details": "Create a new React component `src/features/agents/AlignmentNotification.tsx` that can render a banner or toast based on an `AlignmentResult` object. In the `ChatDock` component, after a user or assistant message is processed, trigger the `lintMessage` service (via a server function). This call must be non-blocking. When the `AlignmentResult` is returned, update the component's state. If a violation is detected, render the `AlignmentNotification` component. Also, use the `createAlignmentEvent` function to log the result to the database asynchronously.",
        "testStrategy": "Use UI component tests (e.g., with Storybook or Vitest) to test the `AlignmentNotification` component with different `AlignmentResult` inputs. In `ChatDock` component tests, simulate the asynchronous return of a linting result and verify that the notification appears without having blocked the initial message rendering or streaming. Confirm that the `createAlignmentEvent` function is called.",
        "priority": "high",
        "dependencies": [
          6,
          7,
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Build Alignment Log Viewer Page and API",
        "description": "Create a new page and supporting API to allow users to query, view, and analyze the persisted alignment events, providing observability into agent behavior.",
        "details": "Create the `alignment-metrics.ts` module to compute aggregate stats from events. Then, implement the TanStack Start route at `src/routes/agents/alignment-log.route.tsx`. The route's `loader` function will call `listAlignmentEvents` (from Task 7) and `computeAlignmentMetrics`, passing filter parameters from the URL search params. The component will render an interactive UI with filter controls (date range, repo, status), a summary metrics display, and a paginated table of alignment events. Each event should be expandable to show details like the message excerpt and the violated rule text.",
        "testStrategy": "Write an integration test for the `/agents/alignment-log` route endpoint, mocking the database calls, to ensure the loader returns the correct data structure based on filter query parameters. Use UI tests to validate the client-side experience, including interacting with filters, paginating through results, and viewing event details. Ensure the page handles empty states and loading states correctly.",
        "priority": "medium",
        "dependencies": [
          7
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-11-27T19:49:28.162Z",
      "updated": "2025-11-27T19:49:28.162Z",
      "description": "Tasks for master context"
    }
  }
}