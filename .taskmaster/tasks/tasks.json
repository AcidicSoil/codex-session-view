{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Establish Foundational AI Configuration and Logging",
        "description": "Create a centralized module for AI-related configuration and a lightweight logging utility. This forms the foundation for all subsequent AI and guardrail modules, loading secrets and settings from the environment.",
        "details": "Implement `src/lib/config/ai-config.ts` to load environment variables (e.g., API keys, base URLs) for different AI providers. Create a function `getAiConfig()` that validates the config and a function `listAvailableModels()` that returns model descriptors. Also, implement `src/lib/observability/logging.ts` with simple `logInfo` and `logError` functions that can be used server-side.",
        "testStrategy": "Unit test `ai-config.ts` by mocking `process.env` to verify successful loading and validation logic, including error handling for missing keys. For logging, unit test to ensure log functions can be called without throwing errors, especially in failure scenarios.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement AI Provider and Model Registry",
        "description": "Set up an AI SDK provider registry in `src/lib/ai/providers.ts` that centralizes all providers and models, exposing helpers that resolve simple string IDs (for language, embedding, and image models) into concrete AI SDK model instances. This decouples model selection from call sites and mirrors the official provider-management pattern.",
        "details": "Create a `registry` using `createProviderRegistry` from `ai`, wiring in providers for OpenAI-compatible endpoints (OpenAI, LM Studio, Gateway-style HTTP), and leaving room to plug in Anthropic, Gemini, and local/in-browser providers as configuration becomes available. Read all API keys, base URLs, and default settings from `getAiConfig()` (Task 1) so that provider configuration lives in one place. Use `customProvider`, `wrapLanguageModel`, and `defaultSettingsMiddleware` to define a small, opinionated set of aliased models (for example: `openai:gpt-4.1`, `openai:gpt-4.1-mini`, `anthropic:sonnet`, `local:dev`), preconfiguring provider options such as reasoning effort, temperature, and max tokens per alias. Export from this module: (1) `registry` itself, (2) `resolveLanguageModel(modelId: string)` that internally calls `registry.languageModel(modelId)`, (3) `resolveEmbeddingModel(modelId: string)` using `registry.textEmbeddingModel(modelId)`, (4) `resolveImageModel(modelId: string)` using `registry.imageModel(modelId)`, and (5) a backwards-compatible `resolveModel(modelId: string)` that currently delegates to `resolveLanguageModel` and is intended for the chat orchestrator. All helpers must accept IDs in the `provider:model` form (e.g., `openai:gpt-4.1`) and throw clear, developer-friendly errors when the provider or model alias is unknown. Keep the public API generic enough that adding a new provider or alias is done by editing the registry configuration rather than touching call sites.",
        "testStrategy": "Unit test the registry helpers by mocking `getAiConfig` and verifying that (1) known IDs resolve to the correct underlying provider instances for language, embedding, and image models, (2) provider options (API key, base URL, reasoning settings, etc.) are passed through as configured, and (3) unknown provider IDs and model aliases throw descriptive errors. Add a small table-driven test that iterates over all documented aliases (e.g., `openai:gpt-4.1`, `local:dev`) to ensure the registry stays in sync with the configuration.",
        "priority": "high",
        "dependencies": [1],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Implement AGENTS.md Loader and Parser",
        "description": "Create a module `src/lib/agents/agents-rules.ts` to locate, load, and parse AGENTS.md files from a given repository context into a structured, normalized ruleset object. This will serve as the source of truth for the alignment linter.",
        "details": "Implement `loadAgentsRules(repoRef, path)` which resolves the AGENTS.md file according to specification (root + nested overrides). The parser should convert the Markdown content into a structured object, e.g., `{ sections: { commands: { text: '...', rules: [{id: 'c1', text: '...'}, ...] } } }`. Implement caching per repo/path to improve performance.",
        "testStrategy": "Unit test the parser with various synthetic AGENTS.md file contents, including malformed ones. Test the file resolver logic for root and nested paths. Use snapshot testing to validate the structure of the parsed output.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Define and Persist Alignment Events",
        "description": "Establish the database schema for `AlignmentEvent` and implement the persistence logic in `src/lib/agents/alignment-events.ts`. This includes functions to create and query alignment events, which will be used by the linter and the analytics UI.",
        "details": "Define the `AlignmentEvent` TypeScript type based on the PRD. Use TanStack DB or a similar persistence layer. Create an async function `createAlignmentEvent(eventData)` that writes a new event to the `alignment_events` table/collection. Also, create `listAlignmentEvents(filters)` for querying with pagination. Ensure persistence failures are non-blocking for core chat flows.",
        "testStrategy": "Test the persistence functions against a test database or in-memory equivalent. Verify that created events match the input data and that filters (by date, repo, status) and pagination in `listAlignmentEvents` work as expected. Check index usage on key filter fields.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Build the Core Chat Orchestrator",
        "description": "Implement the main server-side chat orchestrator in `src/lib/ai/orchestrator.ts`. This function will handle streaming responses, context management, and tool invocation uniformly across all supported AI providers using the Vercel AI SDK.",
        "details": "Create a primary server function `streamChat({ messages, modelId, context })`. This function will use the `resolveModel` from Task 2 to get a provider instance. It will then call the Vercel AI SDK's `streamText` function, passing messages and any provided context. The function should return a `StreamingTextResponse`.\n```typescript\n// src/lib/ai/orchestrator.ts\nimport { streamText } from 'ai';\nimport { resolveModel } from './providers';\n\nexport async function streamChat(request: ChatRequest) {\n  const model = resolveModel(request.modelId);\n  const result = await streamText({\n    model: model,\n    messages: request.messages,\n    system: request.systemPrompt\n  });\n  return result.toAIStreamResponse();\n}\n```",
        "testStrategy": "Create integration tests that call `streamChat` and mock the AI provider's response. Verify that the output is a valid streaming response. Test error handling when a provider fails or a model ID is invalid. Ensure latency is measured and logged.",
        "priority": "high",
        "dependencies": [
          2
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Codex Session Context Attachment Pipeline",
        "description": "Develop the logic in `src/lib/ai/context-codex-session.ts` to transform a Codex session object into a structured context blob or system prompt suitable for an LLM. This makes the chat truly session-aware.",
        "details": "Create `buildSessionContext(session)` to normalize session data and `createContextPrompt(context)` to generate a concise summary. The prompt should include repo, branch, a summary of messages, and key file names, while respecting size limits and redaction rules. This context will be fed into the orchestrator's system prompt.",
        "testStrategy": "Unit test with various synthetic `CodexSession` objects. Verify that the generated context prompt is well-formed, respects token/character limits, and correctly redacts sensitive information if rules are defined. Snapshot test the output prompts for consistency.",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement AGENTS Alignment Linter",
        "description": "Create the `agents-linter` module to classify user and assistant messages against the loaded AGENTS.md ruleset. This module will also be responsible for generating remediation prompts for misaligned messages.",
        "details": "In `src/lib/agents/agents-linter.ts`, implement `lintMessage({ message, ruleset })`. Start with deterministic heuristics, like checking for forbidden commands or file paths mentioned in the rules. The function should return an `AlignmentResult` object: `{status: 'aligned' | 'warn' | 'block', violatedRules: [...]}`. Also, implement `buildRemediation(result)` to generate a helpful correction prompt.",
        "testStrategy": "Write extensive unit tests for the linter. For each rule type, create test cases with messages that should pass, warn, or fail. Use snapshot tests for the generated remediation prompts to ensure they are helpful and consistent.",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Integrate Linter with Alignment Event Logging",
        "description": "Connect the AGENTS linter to the alignment event persistence layer. After each message is linted, the result should be logged as a structured `AlignmentEvent` in the database.",
        "details": "Modify the workflow that calls `lintMessage` (likely within or alongside the orchestrator). After receiving the `AlignmentResult`, call the `createAlignmentEvent` function from Task 4, mapping the result fields (status, violatedRules, etc.) and message metadata to the event schema. This should be an async, non-blocking operation.",
        "testStrategy": "Write an integration test that takes a message, runs it through the linter, and verifies that the correct `AlignmentEvent` is created in the test database. Check that all fields, including session ID, message excerpt, and rule IDs, are populated correctly.",
        "priority": "medium",
        "dependencies": [
          4,
          7
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Wire Session Context into Codex Viewer Route Loader",
        "description": "Extend the TanStack Start route loader for the `codex-session-viewer.route.tsx` to fetch and provide session-specific context, including the parsed AGENTS.md ruleset, to the UI components.",
        "details": "In the `loader` function for the session viewer route, use the `buildSessionContext` (Task 6) and `loadAgentsRules` (Task 3) functions. The loader should fetch the raw session data and then transform it into `SessionContext` and `AgentsRuleset` objects. These will be made available to the `ChatDock` component via props or a React context provider, ensuring no client-side fetching.",
        "testStrategy": "Write an integration test for the route loader. Mock the underlying data-fetching for a session and verify that the loader's output contains the correctly structured `SessionContext` and `AgentsRuleset` objects. Ensure the data is available for SSR.",
        "priority": "medium",
        "dependencies": [
          3,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Refactor ChatDock UI to Use the AI Orchestrator",
        "description": "Refactor the existing `ChatDock.tsx` component to remove any ad-hoc, direct AI calls and instead use a client-side hook that communicates with the new server-side chat orchestrator.",
        "details": "Create a TanStack Query mutation or a simple fetch-based client to call a new server function that wraps the `streamChat` orchestrator (Task 5). Replace the current `useEffect`-based or direct SDK calls in `ChatDock.tsx` with this new client. The component should receive session context from its parent via props (provided by Task 9's loader). Use the Vercel AI SDK's `useChat` or `useCompletion` hooks if they fit TanStack Start's architecture, or handle the streaming response manually.",
        "testStrategy": "Use component tests (e.g., with Vitest and Testing Library) to test the refactored `ChatDock`. Mock the orchestrator client API. Verify that user messages are sent correctly and that streaming responses are rendered as they arrive.",
        "priority": "high",
        "dependencies": [
          5,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Inline Alignment Notifications in UI",
        "description": "Create and integrate the `AlignmentNotification.tsx` component into `ChatDock` to display non-blocking warnings and remediation suggestions when a message is flagged by the AGENTS linter.",
        "details": "Create a new server endpoint that runs the linter (Task 7) for a given message. This should be called from the `ChatDock` component asynchronously whenever a message is sent or received. When an alignment result with `status: 'warn'` is returned, render an `AlignmentBanner` or `MessageAlignmentBadge` component with the violation details and the suggested remediation text from the linter.",
        "testStrategy": "In component tests for `ChatDock`, mock the linter API endpoint to return different `AlignmentResult` statuses. Verify that the correct notification UI (banner, toast, or badge) is displayed for 'warn' status and that nothing is shown for 'aligned'. Test that the remediation prompt can be easily used by the user.",
        "priority": "medium",
        "dependencies": [
          8,
          10
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Build the Alignment Log Viewer Page",
        "description": "Create a new route and UI at `/agents/alignment-log` for viewing, filtering, and searching through the persisted alignment events. This page is for AI/DX owners to analyze agent behavior.",
        "details": "Implement `src/routes/agents/alignment-log.route.tsx`. The route's loader should call `listAlignmentEvents` (Task 4), passing filter parameters from the URL search params (e.g., `?repo=...&status=warn`). The component should render a filter bar and a table or list of the returned events. Each event should show key details and link back to the original Codex session.",
        "testStrategy": "Write an integration test for the route, mocking the database to return a predefined set of alignment events. Verify that the loader returns the correct data based on filter params. Use UI component tests to validate that the table and filter controls render and function correctly.",
        "priority": "low",
        "dependencies": [
          4,
          8
        ],
        "status": "pending",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-11-24T00:51:33.286Z",
      "updated": "2025-11-24T00:51:33.286Z",
      "description": "Tasks for master context"
    }
  }
}