{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement AI Provider Abstraction (lib/ai)",
        "description": "Create a provider-agnostic LLM abstraction using the Vercel AI SDK and define shared prompt templates for chat, summaries, and commit messages. This is a foundational module for all AI-powered features.",
        "details": "Create a `lib/ai` directory with `provider.ts`, `prompt-templates.ts`, and `index.ts`. The `provider.ts` file will encapsulate the Vercel AI SDK model selection and streaming logic, exporting a unified `streamChat` function. The `prompt-templates.ts` file will contain functions to build standardized prompts for different tasks (e.g., `buildSummaryPrompt(context)`). This module ensures that the rest of the application is decoupled from specific LLM providers.",
        "testStrategy": "Unit test the prompt template construction with contract tests. Mock the Vercel AI SDK to unit test the `streamChat` wrapper, verifying correct argument passing and error handling. This module should have no direct E2E tests but will be covered by integration tests of dependent features.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Setup AI Provider Wrapper in `lib/ai/provider.ts`",
            "description": "Create the core provider abstraction that encapsulates the Vercel AI SDK. This task involves setting up the file structure and implementing a unified `streamChat` function to handle model selection and streaming logic.",
            "dependencies": [],
            "details": "Create the `lib/ai` directory with `provider.ts` and `index.ts`. The `provider.ts` file will wrap the Vercel AI SDK's `streamText` function, exporting a single `streamChat` function. This function will manage model selection and API key handling via environment variables.",
            "status": "pending",
            "testStrategy": "Unit tests will be created in a subsequent task to mock the underlying SDK and verify correct argument passing and error handling."
          },
          {
            "id": 2,
            "title": "Implement Initial Prompt Template Functions",
            "description": "Create standardized functions for building prompts for general chat conversations and content summarization. This will ensure consistent and maintainable prompts across different features.",
            "dependencies": [
              1
            ],
            "details": "Create `lib/ai/prompt-templates.ts`. Implement and export `buildChatPrompt(messages)` and `buildSummaryPrompt(context)`. These functions will format input data into the structure required by the `streamChat` function defined in the provider. Update `index.ts` to export them.",
            "status": "pending",
            "testStrategy": "Contract tests will be implemented in a subsequent task to ensure the output of each template function adheres to a predefined structure and content format for given inputs."
          },
          {
            "id": 3,
            "title": "Implement Unit Tests for the AI Abstraction Layer",
            "description": "Write comprehensive unit tests for the AI provider wrapper and the prompt template functions to ensure their correctness, reliability, and prevent regressions.",
            "dependencies": [
              1,
              2
            ],
            "details": "Create test files (e.g., `provider.test.ts`, `prompt-templates.test.ts`). Mock the Vercel AI SDK using a test framework to validate the `streamChat` wrapper's logic. Use snapshot testing to verify the output of the prompt builder functions.",
            "status": "pending",
            "testStrategy": "Implement tests using Vitest. For the provider, use `vi.mock` to isolate it from external services. For prompts, use snapshot testing to easily validate complex string outputs against known good versions."
          }
        ]
      },
      {
        "id": 2,
        "title": "Implement AGENTS.md Rules Parser (lib/agents-rules)",
        "description": "Develop a module to parse the `AGENTS.md` markdown file into a structured, queryable set of rules. This enables programmatic access to architectural constraints and anti-patterns.",
        "details": "Create a `lib/agents-rules` directory containing `parser.ts`. Use a markdown AST library like `unified` with `remark-parse` to traverse the document. Extract rules from headings and bulleted lists. Support metadata extraction from HTML comments (e.g., `<!-- rule-id: AGENTS-001, severity: high -->`). The module should export `loadAgentsRules(content)` and query functions like `getRuleById(id)`.",
        "testStrategy": "Use snapshot tests to validate the output of parsing a sample `AGENTS.md` file. Write unit tests for edge cases, such as malformed markdown or missing annotations, ensuring the parser is resilient. Test the query API to confirm correct rule lookups.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up Markdown AST Parser with `unified` and `remark-parse`",
            "description": "Initialize the `lib/agents-rules` directory and create `parser.ts`. Set up the basic parsing pipeline using the `unified` and `remark-parse` libraries to convert a given markdown string into a syntax tree (MDAST).",
            "dependencies": [],
            "details": "Create the `lib/agents-rules` directory. In `parser.ts`, install `unified`, `remark-parse`, and their types. Implement a basic function that takes markdown content as a string and returns the resulting AST.",
            "status": "pending",
            "testStrategy": "Manually verify that a sample markdown string is correctly parsed into a recognizable AST structure by logging the output to the console during development."
          },
          {
            "id": 2,
            "title": "Implement AST Traversal to Extract Rule Structures",
            "description": "Build the core logic to traverse the MDAST. Identify rule sections based on markdown structure (e.g., a heading followed by a list) and extract their title, description, and raw content into an intermediate data structure.",
            "dependencies": [
              1
            ],
            "details": "Use a visitor pattern library like `unist-util-visit` to walk the AST. The logic should identify `heading` nodes as the start of a rule and collect all subsequent sibling nodes until the next heading of the same or higher level.",
            "status": "pending",
            "testStrategy": "Write unit tests using simple markdown strings as input. Assert that the traversal logic correctly identifies the number of rules and extracts the correct heading text and list items for each rule."
          },
          {
            "id": 3,
            "title": "Parse Rule Metadata from HTML Comments",
            "description": "Enhance the AST traversal logic to find and parse HTML comments (e.g., `<!-- rule-id: AGENTS-001, severity: high -->`) associated with each rule. Extract key-value pairs into a metadata object.",
            "dependencies": [
              2
            ],
            "details": "Within the AST traversal, inspect `html` nodes for comment patterns. Use regular expressions to parse the key-value pairs inside the comment. This metadata should be attached to the rule object being constructed.",
            "status": "pending",
            "testStrategy": "Create unit tests with markdown samples that include valid metadata comments, malformed comments, comments with extra whitespace, and rules with missing comments to ensure the parser is resilient."
          },
          {
            "id": 4,
            "title": "Implement Public API and Add Integration/Snapshot Tests",
            "description": "Expose the final public API for the module, including `loadAgentsRules(content)` to run the full parsing process and `getRuleById(id)` to query the parsed rules. Add comprehensive unit and snapshot tests.",
            "dependencies": [
              3
            ],
            "details": "Implement the exported functions `loadAgentsRules` and `getRuleById`. The `loadAgentsRules` function will orchestrate the full parsing logic and return a structured array of rules. Create a sample `AGENTS.md` file in a `__fixtures__` directory and use snapshot testing to validate the entire parsed output.",
            "status": "pending",
            "testStrategy": "Use Jest to create a snapshot test for the `loadAgentsRules` function against a representative `AGENTS.md` fixture file. Add unit tests for `getRuleById` to confirm successful lookups and correct handling of non-existent IDs."
          }
        ]
      },
      {
        "id": 3,
        "title": "Define Canonical Session Model (lib/sessions)",
        "description": "Establish the core TypeScript data structures for sessions and events (`Session`, `SessionEvent`) that will be used consistently across the entire application, from the viewer to the chatbot.",
        "details": "Create a `lib/sessions/model.ts` file. Define and export TypeScript interfaces for `Session`, `SessionEvent`, `ProviderId`, and other related entities as described in the PRD. The goal is to create a single source of truth for session data. Ensure that the existing viewer can be refactored to use these new types with minimal friction.",
        "testStrategy": "Leverage TypeScript's static analysis for type-level testing. Additionally, use a runtime validation library like Zod to create schemas from the interfaces and validate sample session data objects to ensure they conform to the expected shape at runtime.",
        "priority": "high",
        "dependencies": [],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Core TypeScript Interfaces for Session and SessionEvent",
            "description": "Create the foundational TypeScript interfaces (`Session`, `SessionEvent`, `ProviderId`) in a new file to serve as the single source of truth for session data structures across the application.",
            "dependencies": [],
            "details": "Create the file `lib/sessions/model.ts`. Within this file, define and export the TypeScript interfaces for `Session`, `SessionEvent`, `ProviderId`, and any other necessary related types as outlined in the project requirements.",
            "status": "pending",
            "testStrategy": "Leverage TypeScript's static analysis by running `tsc --noEmit`. This will confirm that the types are well-formed and can be imported without issues. No runtime tests are required for this step."
          },
          {
            "id": 2,
            "title": "Implement Zod Schemas for Session Model Runtime Validation",
            "description": "Develop Zod schemas that correspond to the newly defined `Session` and `SessionEvent` interfaces to enable robust runtime validation of data.",
            "dependencies": [
              1
            ],
            "details": "In `lib/sessions/model.ts` or a new validation-specific file, implement and export Zod schemas that accurately reflect the structure of the `Session` and `SessionEvent` interfaces. Use `z.infer` to derive types from the schemas where possible to ensure they remain synchronized.",
            "status": "pending",
            "testStrategy": "Create unit tests that attempt to parse various valid and invalid mock session data objects using the new Zod schemas. Assert that valid data passes and invalid data throws the expected validation errors."
          },
          {
            "id": 3,
            "title": "Refactor Viewer Component to Adopt Canonical Session Types",
            "description": "Update the existing session viewer component to utilize the new canonical `Session` and `SessionEvent` types and Zod schemas, removing any old or local type definitions.",
            "dependencies": [
              1,
              2
            ],
            "details": "Modify the file `src/routes/(site)/viewer/index.tsx`. Replace any existing session-related types with imports from `lib/sessions/model.ts`. Use the Zod schemas to parse and validate any session data being passed into the component.",
            "status": "pending",
            "testStrategy": "Manually perform regression testing on the viewer UI to ensure all features work as before. Check the browser console for any new type-related warnings or Zod validation errors. If E2E tests exist for the viewer, ensure they continue to pass."
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Session Context Builder (features/chatbot/context-builder)",
        "description": "Develop a module to transform raw, lengthy session data into a compact, token-bounded context object suitable for LLM prompts.",
        "details": "Create `features/chatbot/context-builder.ts`. This module will export a function `buildSessionContext(session: Session)` that receives a session object and returns a structured summary. The implementation should apply deterministic summarization, such as bucketing events into 'recent N events', 'critical errors', and 'user goals'. Crucially, it must enforce a token budget, intelligently trimming less important information first to avoid exceeding provider limits. Implement caching per session ID to optimize performance across multiple turns.",
        "testStrategy": "Unit test the context builder with a variety of synthetic session objects (e.g., very long, very short, error-heavy) to verify the summarization logic. Write specific boundary tests for the token budget enforcement to ensure it trims context correctly and gracefully.",
        "priority": "high",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Basic Context Summarization and Event Bucketing",
            "description": "Create the initial structure of the `buildSessionContext` function to process a raw session object and categorize its events into deterministic buckets such as 'recent N events', 'critical errors', and 'user goals'.",
            "dependencies": [],
            "details": "In `features/chatbot/context-builder.ts`, define the `buildSessionContext` function. This initial pass will focus on iterating through session events and classifying them into a structured object, without yet considering token limits.",
            "status": "pending",
            "testStrategy": "Unit test the function with various mock session objects to confirm that events are correctly sorted into their respective buckets (e.g., error logs land in 'critical errors')."
          },
          {
            "id": 2,
            "title": "Create a Token Counting Utility",
            "description": "Develop a utility function to accurately estimate the number of tokens for a given string or context object. This is a prerequisite for enforcing the token budget.",
            "dependencies": [],
            "details": "Implement a `countTokens(content: any)` helper function. This function will likely use a library like `gpt-tokenizer` to serialize the context object to a string and then calculate the token count, mimicking how the LLM provider would see it.",
            "status": "pending",
            "testStrategy": "Test the utility with a range of inputs: simple strings, complex JSON objects, and edge cases like empty or very long text. Compare the output against known token counts for a target model."
          },
          {
            "id": 3,
            "title": "Develop Intelligent Truncation Algorithm for Token Budgeting",
            "description": "Enhance the context builder to enforce a strict token budget. This involves implementing a prioritization scheme to intelligently trim or summarize less critical information first.",
            "dependencies": [
              1,
              2
            ],
            "details": "Integrate the token counting utility into `buildSessionContext`. Implement logic that iteratively builds the context, checking the token count at each stage. If the budget is exceeded, apply truncation rules, starting with the lowest priority data (e.g., older, non-critical events).",
            "status": "pending",
            "testStrategy": "Write specific boundary tests using session data designed to be slightly under, exactly at, and over the token limit. Verify that the output context respects the budget and that the highest priority information is preserved."
          },
          {
            "id": 4,
            "title": "Add Session-Based Caching to Optimize Performance",
            "description": "Implement an in-memory caching layer for the context builder to avoid redundant computations for the same session across multiple chatbot turns.",
            "dependencies": [
              3
            ],
            "details": "Wrap the `buildSessionContext` logic with a caching mechanism. Use a `Map` or a similar structure, keyed by session ID. Before executing the build logic, check for a cached result. If found, return it; otherwise, compute the context, store it in the cache, and then return.",
            "status": "pending",
            "testStrategy": "Write tests to verify that for a given session ID, the core context generation logic is invoked only on the first call. Subsequent calls should return the cached result. Also, test that different session IDs result in cache misses and new computations."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement Automatic Misalignment Detector (features/chatbot/misalignment-detector)",
        "description": "Create the core logic to automatically detect violations of AGENTS rules from session data using a hybrid approach of fast heuristics and LLM-based classification.",
        "details": "Create `features/chatbot/misalignment-detector.ts`. Implement the main function `detectMisalignments(session, rules)`. This function will run a pipeline: first, apply fast, deterministic heuristic checks for simple rules (e.g., using regex to find 'fetch' inside a 'useEffect' log). For more complex, nuanced rules, it will use the context builder and AI provider library to prompt an LLM for classification. The output should be a structured list of `Misalignment` objects.",
        "testStrategy": "Unit test the heuristic checks with targeted, synthetic session events. For the LLM-based detection, write integration tests that use a mocked LLM interface to verify correct prompt construction and handling of the LLM's classification response. Test the fallback behavior when the AI provider fails.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Design and Stub Main `detectMisalignments` Pipeline",
            "description": "Create the core file `features/chatbot/misalignment-detector.ts` and define the main `detectMisalignments(session, rules)` function. This function will serve as the orchestrator for both heuristic and LLM-based detection paths.",
            "dependencies": [],
            "details": "In `features/chatbot/misalignment-detector.ts`, implement the basic structure of the `detectMisalignments` function. It should accept `session` and `rules` arguments. Define the `Misalignment` type and the high-level logic for routing rules to either a heuristic or an LLM check using placeholder functions.",
            "status": "pending",
            "testStrategy": "Write a basic unit test to confirm the `detectMisalignments` function can be called and returns an empty array by default. This ensures the initial file and function signature are correct."
          },
          {
            "id": 2,
            "title": "Implement Fast-Path Heuristic Rule Checks",
            "description": "Develop the logic for fast, deterministic rule checks that can identify simple violations using methods like regular expressions against session data. This handles the 'fast path' of the hybrid approach.",
            "dependencies": [
              1
            ],
            "details": "Create a helper function, e.g., `runHeuristicChecks(session, rules)`. This function will filter for rules that can be checked deterministically (e.g., via a regex pattern defined in the rule object). It will scan session events and return an array of `Misalignment` objects for any violations found.",
            "status": "pending",
            "testStrategy": "Unit test the heuristic checker with synthetic session events. For a rule like 'no fetch in useEffect', provide logs that both violate and adhere to the rule, and assert that the function correctly identifies only the violations."
          },
          {
            "id": 3,
            "title": "Integrate AI Provider for Complex Rule Classification",
            "description": "Implement the logic to use an LLM for classifying violations of complex, nuanced rules that cannot be checked with simple heuristics. This involves prompt construction and calling the AI provider library.",
            "dependencies": [
              1
            ],
            "details": "Create a function `runLLMChecks(session, complexRules)`. This will use the `context-builder` (Task 4) to get a summarized session context, construct a detailed prompt asking the LLM to classify violations against the provided rules, and then call the AI provider. The prompt must explicitly request a structured JSON response.",
            "status": "pending",
            "testStrategy": "Use an integration test with a mocked LLM interface. Verify that a well-formed prompt is constructed based on sample session data and rules. Test the error handling for when the AI provider API call fails."
          },
          {
            "id": 4,
            "title": "Implement Parser for Structured LLM Responses",
            "description": "Develop a robust parser to process the structured JSON response from the LLM. This includes validating the response format and safely converting the data into an array of `Misalignment` objects.",
            "dependencies": [
              3
            ],
            "details": "Create a parsing and validation function that takes the raw string output from the LLM. Use a schema validation library like Zod to ensure the response conforms to the expected structure. Implement robust error handling for malformed JSON, missing fields, or incorrect data types to prevent crashes.",
            "status": "pending",
            "testStrategy": "Unit test the parser against various LLM outputs: a perfect JSON string, a string with syntax errors, valid JSON with missing properties, and JSON with incorrect data types. Ensure it handles each case gracefully."
          },
          {
            "id": 5,
            "title": "Unify Heuristic and LLM Results into Final List",
            "description": "Update the main `detectMisalignments` function to combine the results from both the fast-path heuristic checks and the LLM-based classification into a single, unified list of `Misalignment` objects.",
            "dependencies": [
              2,
              4
            ],
            "details": "Within the main `detectMisalignments` function, invoke the `runHeuristicChecks` and `runLLMChecks` functions. Take the resulting arrays of `Misalignment` objects from both and concatenate them into a single list. Ensure the final returned list is correctly formatted and free of duplicates.",
            "status": "pending",
            "testStrategy": "Write an integration test for the `detectMisalignments` orchestrator. Use a test session that should trigger both a heuristic violation and an LLM-detected violation. Mock the LLM response and assert that the final returned list correctly contains both misalignments."
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Artifact Generation Logic (summaries & commit-messages)",
        "description": "Implement the backend logic for generating session summaries and conventional commit messages based on session context.",
        "details": "In the `features/chatbot/` directory, create `summaries.ts` and `commit-messages.ts`. Implement `generateSummary(context, options)` and `generateCommitMessages(context, options)`. These functions will take the output from the `context-builder` (Task 4), use prompt templates from `lib/ai` (Task 1), and call the LLM to generate the respective artifacts. The commit message generator should support style configurations like Conventional Commits.",
        "testStrategy": "Use golden-file or snapshot testing to ensure consistent and high-quality output for a set of benchmark sessions. This helps prevent regressions in generation quality. Unit test the commit message generator's adherence to different style configurations.",
        "priority": "high",
        "dependencies": [
          1,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Session Summary Generation Logic",
            "description": "Create the `generateSummary` function in `features/chatbot/summaries.ts` to produce a concise summary of a session from a given context.",
            "dependencies": [],
            "details": "In the `features/chatbot/` directory, create a new file named `summaries.ts`. Implement and export an async function `generateSummary(context, options)` that takes a context object from the context-builder and uses a prompt template from `lib/ai` to invoke the LLM for a session summary.",
            "status": "pending",
            "testStrategy": "Unit tests will mock the LLM call and verify that the correct prompt is constructed based on the input context. Full output quality will be validated in a subsequent testing task."
          },
          {
            "id": 2,
            "title": "Implement Base Commit Message Generation Logic",
            "description": "Create the `generateCommitMessages` function in `features/chatbot/commit-messages.ts` to generate initial commit message suggestions based on session context.",
            "dependencies": [],
            "details": "Create the file `features/chatbot/commit-messages.ts`. Implement the base function `generateCommitMessages(context, options)`. This will use a prompt template from `lib/ai` and the session context to ask the LLM for several potential commit messages that reflect the changes in the session.",
            "status": "pending",
            "testStrategy": "Unit tests will mock the LLM provider and check for correct prompt construction. Initial tests should verify that the function returns an array of strings as expected from the mocked provider."
          },
          {
            "id": 3,
            "title": "Add Support for Configurable Commit Message Styles",
            "description": "Enhance the `generateCommitMessages` function to support different formatting styles, such as Conventional Commits, based on an `options` parameter.",
            "dependencies": [
              2
            ],
            "details": "Modify the `generateCommitMessages` function. The `options` object should accept a `style` property (e.g., 'conventional', 'standard'). The prompt sent to the LLM must be dynamically adjusted to include instructions and examples for the requested commit message format.",
            "status": "pending",
            "testStrategy": "Write unit tests that invoke the function with different style options. Mock the LLM and assert that the generated prompt correctly includes instructions for the specified style (e.g., Conventional Commits). "
          },
          {
            "id": 4,
            "title": "Establish Golden-File Testing for Generated Artifacts",
            "description": "Implement a golden-file (snapshot) testing pipeline for both the summary and commit message generation functions to ensure output quality and prevent regressions over time.",
            "dependencies": [
              1,
              2
            ],
            "details": "Using a test runner like Jest, create a new test suite. Define a set of benchmark session context objects saved as files. The tests will execute `generateSummary` and `generateCommitMessages` with this data and store the real LLM output as snapshot files. These serve as 'golden' references to detect quality regressions.",
            "status": "pending",
            "testStrategy": "The implementation of this task is the test strategy itself. The process will involve manual review of the initial golden files to ensure they meet quality standards before they are committed."
          }
        ]
      },
      {
        "id": 7,
        "title": "Implement Chatbot API Server (server/chatbot-api.server.ts)",
        "description": "Create the TanStack Start server functions to handle streaming chat requests and on-demand analysis, serving as the bridge between the frontend and backend logic.",
        "details": "Create `server/chatbot-api.server.ts`. Implement a streaming server function, `chatbotStreamServerFn`, using TanStack Start's `createServerFn`. This function will use the Vercel AI SDK's server-side helpers to handle streaming. It will accept `sessionId` and `messages`, use the `context-builder` (Task 4) and `misalignment-detector` (Task 5) to enrich the context, and call the AI provider. Also, create a non-streaming function, `analyzeSessionServerFn`, to handle requests for summaries and commit messages from the logic in Task 6.",
        "testStrategy": "Write integration tests that directly invoke the server functions with mock request objects. For the streaming endpoint, verify that the response stream is correctly formatted. Test all error paths, such as providing an invalid `sessionId` or simulating an AI provider outage, ensuring the server responds with appropriate error codes.",
        "priority": "high",
        "dependencies": [
          1,
          4,
          5,
          6
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Non-Streaming `analyzeSessionServerFn` for Artifact Generation",
            "description": "Create the `analyzeSessionServerFn` in `server/chatbot-api.server.ts` to handle on-demand requests for session summaries and commit messages. This function will serve as the API endpoint for artifact generation logic from Task 6.",
            "dependencies": [],
            "details": "In the new file `server/chatbot-api.server.ts`, define `analyzeSessionServerFn` using TanStack Start's `createServerFn`. This function will accept a `sessionId` and an `analysisType` ('summary' or 'commitMessage'). It will then call the corresponding functions from Task 6 (`generateSummary` or `generateCommitMessages`) and return the result as a standard JSON response.",
            "status": "pending",
            "testStrategy": "Unit test this function by mocking the underlying artifact generation logic (from Task 6). Verify that it correctly invokes the appropriate service and formats the response based on the `analysisType` input."
          },
          {
            "id": 2,
            "title": "Implement Core Streaming Logic for `chatbotStreamServerFn`",
            "description": "Set up the basic structure for the streaming chat endpoint, `chatbotStreamServerFn`, using TanStack Start's `createServerFn` and the Vercel AI SDK. This will establish the fundamental request/response pipeline for live chat.",
            "dependencies": [],
            "details": "In `server/chatbot-api.server.ts`, define `chatbotStreamServerFn`. Configure it to work with the Vercel AI SDK's server-side helpers like `StreamingTextResponse`. The initial implementation will accept a `sessionId` and `messages`, forward them to the AI provider, and stream the response back to the client.",
            "status": "pending",
            "testStrategy": "Test this endpoint by directly invoking it with a simple message payload and a mocked AI provider. Verify that a `StreamingTextResponse` is returned and that the stream format is correct."
          },
          {
            "id": 3,
            "title": "Integrate Context Builder and Misalignment Detector into Streaming Flow",
            "description": "Enhance the `chatbotStreamServerFn` by integrating the context builder (Task 4) and misalignment detector (Task 5). This will enrich the user's prompt with relevant session data and rule violations before calling the AI.",
            "dependencies": [
              2
            ],
            "details": "Modify `chatbotStreamServerFn`. Before calling the AI provider, use the incoming `sessionId` to fetch session data. Pass this data to the `buildSessionContext` function (Task 4) and `detectMisalignments` function (Task 5). Prepend the generated context to the user's message list to form the final, context-aware prompt for the AI.",
            "status": "pending",
            "testStrategy": "Write unit tests that mock the context builder and misalignment detector modules. Pass a sample `sessionId` and verify that the final prompt sent to the mocked AI provider is correctly constructed and includes the enriched context."
          },
          {
            "id": 4,
            "title": "Write Integration Tests for API Endpoints",
            "description": "Develop a suite of integration tests to validate the functionality, error handling, and data flow of both the `chatbotStreamServerFn` and `analyzeSessionServerFn` server functions.",
            "dependencies": [
              1,
              3
            ],
            "details": "Create a test file for `server/chatbot-api.server.ts`. For `analyzeSessionServerFn`, test calls for both 'summary' and 'commitMessage' types. For `chatbotStreamServerFn`, test the full flow by mocking dependencies and asserting the streamed response content. Crucially, test error paths like invalid session IDs or simulated AI provider outages.",
            "status": "pending",
            "testStrategy": "Use an integration testing framework to invoke the server functions directly. For the streaming test, consume the entire stream and validate its content against a snapshot. For error handling, assert that the functions throw or return appropriate error responses."
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement and Integrate ChatDock UI (components/chatbot/ChatDockPanel.tsx)",
        "description": "Build the primary chat interface as a collapsible dock within the session viewer and connect it to the backend streaming API.",
        "details": "Create `components/chatbot/ChatDockPanel.tsx` using `shadcn/ui` components for the panel structure, text area, and buttons. Use the Vercel AI SDK's `useChat` hook in the component to manage state and connect to the `chatbotStreamServerFn` (from Task 7). Integrate this component into the main viewer route at `src/routes/(site)/viewer/index.tsx`, ensuring it is collapsible to not obstruct the main timeline view.",
        "testStrategy": "Use Cypress or Playwright for E2E tests: simulate a user typing a message, submitting it, and asserting that a streamed response from a mock server appears correctly in the chat history. Add visual regression tests to catch unintended UI changes to the dock's layout and style.",
        "priority": "medium",
        "dependencies": [
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Scaffold ChatDockPanel UI with shadcn/ui Components",
            "description": "Create the initial `ChatDockPanel.tsx` file and build the static UI layout using `shadcn/ui` components. This includes the main panel, message list area, text input, and send button.",
            "dependencies": [],
            "details": "Create the file `components/chatbot/ChatDockPanel.tsx`. Use `<Card>`, `<ScrollArea>`, `<Textarea>`, and `<Button>` from `shadcn/ui` to structure the visual layout of the chat interface, focusing on a clean, static presentation without state logic.",
            "status": "pending",
            "testStrategy": "Use Storybook to visually inspect the component in isolation. Add visual regression tests to capture the baseline appearance of the panel, input area, and message list."
          },
          {
            "id": 2,
            "title": "Integrate Vercel AI SDK `useChat` Hook",
            "description": "Wire up the `ChatDockPanel` component with the `useChat` hook from the Vercel AI SDK to manage chat messages, input state, and connect to the backend streaming API.",
            "dependencies": [
              1
            ],
            "details": "Import and invoke `useChat` within `ChatDockPanel.tsx`. Configure its `api` option to target the server function route. Connect the hook's `messages`, `input`, `handleInputChange`, and `handleSubmit` to the UI components and their event handlers.",
            "status": "pending",
            "testStrategy": "Unit test the component with a mocked `useChat` hook to verify that messages are rendered correctly and that input changes and form submissions call the appropriate hook functions."
          },
          {
            "id": 3,
            "title": "Implement Collapsible and Expandable Dock Behavior",
            "description": "Add state and logic to allow the `ChatDockPanel` to be collapsed to a minimal state and expanded back to its full view, ensuring it doesn't permanently obstruct the main session viewer content.",
            "dependencies": [
              1
            ],
            "details": "Use a React state hook (e.g., `useState`) to manage the `isCollapsed` state. Add a toggle button and use conditional CSS classes to change the component's size and visibility of its contents based on the state. Animate the transition for a smoother UX.",
            "status": "pending",
            "testStrategy": "Write a Cypress/Playwright test to click the toggle button and assert that the component's dimensions and content visibility change as expected. Use visual regression tests for both collapsed and expanded states."
          },
          {
            "id": 4,
            "title": "Integrate ChatDockPanel into the Session Viewer Page",
            "description": "Place the completed `ChatDockPanel` component into the main session viewer page (`src/routes/(site)/viewer/index.tsx`), ensuring it is positioned correctly and functions within the larger application layout.",
            "dependencies": [
              2,
              3
            ],
            "details": "Import and render the `ChatDockPanel` component within `src/routes/(site)/viewer/index.tsx`. Position it using CSS, likely with `position: fixed` in a corner of the viewport. Ensure it does not conflict with other UI elements and that all functionality works as expected.",
            "status": "pending",
            "testStrategy": "Perform an E2E test on the viewer page. Verify the chat dock appears, can be collapsed/expanded, and that a full chat interaction (sending a message, receiving a streamed response) works correctly in the integrated environment."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement Misalignment Notification UI (MisalignmentBanner, TimelineBadges)",
        "description": "Create the UI components to visually notify the user of detected AGENTS rule misalignments, including a top banner and markers on the session timeline.",
        "details": "Create `components/chatbot/MisalignmentBanner.tsx` and `MisalignmentTimelineBadges.tsx`. These components will fetch data from an analysis endpoint (part of Task 7) that provides misalignment data from the detector (Task 5). The banner should be non-modal and display a summary of findings. Clicking the banner or a timeline badge should open the ChatDock (Task 8) with a pre-filled remediation prompt related to the specific misalignment.",
        "testStrategy": "Write E2E tests using a session fixture known to produce misalignments, and assert that the banner and timeline badges appear correctly. Unit test the components' rendering logic for various states (e.g., no misalignments, one, multiple) and verify that the click handlers trigger the correct actions.",
        "priority": "medium",
        "dependencies": [
          5,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Build MisalignmentBanner Component with Data Fetching",
            "description": "Create the `MisalignmentBanner.tsx` component. It should fetch misalignment data from the analysis endpoint and display a summary of the findings in a non-modal banner at the top of the page.",
            "dependencies": [],
            "details": "Create the file `components/chatbot/MisalignmentBanner.tsx`. Use TanStack Query to call the `analyzeSessionServerFn` (from Task 7) to get misalignment data. The component should handle loading and error states and display a summary when data is available.",
            "status": "pending",
            "testStrategy": "Unit test the component's rendering logic for various states, including loading, error, no misalignments, and one or more misalignments. Mock the server function to provide test data."
          },
          {
            "id": 2,
            "title": "Create MisalignmentTimelineBadges Component",
            "description": "Create the `MisalignmentTimelineBadges.tsx` component which will be responsible for rendering the visual markers on the session timeline.",
            "dependencies": [],
            "details": "Create `components/chatbot/MisalignmentTimelineBadges.tsx`. This component will receive an array of misalignment objects as props and be responsible for mapping them to individual badge markers. The single badge marker can be a sub-component.",
            "status": "pending",
            "testStrategy": "Use Storybook to develop the badge component in isolation. Create stories to verify its appearance with different types of misalignment data."
          },
          {
            "id": 3,
            "title": "Integrate Timeline Badges into Session Timeline",
            "description": "Modify the existing session timeline component to render the `MisalignmentTimelineBadges` component, passing it the necessary misalignment data.",
            "dependencies": [
              1,
              2
            ],
            "details": "In the main session viewer component, reuse the data-fetching logic from the `MisalignmentBanner` to get misalignment data. Pass this data as a prop to the `MisalignmentTimelineBadges` component, which should be placed within the timeline's rendering logic.",
            "status": "pending",
            "testStrategy": "Write an E2E test using a session fixture known to have misalignments. Assert that the badges are rendered on the timeline in the correct positions corresponding to the event timestamps."
          },
          {
            "id": 4,
            "title": "Implement Cross-Component Click-to-Open ChatDock Logic",
            "description": "Implement the functionality where clicking the banner or a timeline badge opens the `ChatDock` (from Task 8) with a pre-filled, context-specific remediation prompt.",
            "dependencies": [
              1,
              3
            ],
            "details": "Use a global state management solution (e.g., Zustand or React Context) to manage the ChatDock's open state and initial prompt text. Add `onClick` handlers to `MisalignmentBanner` and the individual badges that update this shared state.",
            "status": "pending",
            "testStrategy": "Write an E2E test that clicks a badge, then asserts that the ChatDock panel opens and its input field contains the expected remediation prompt text."
          }
        ]
      },
      {
        "id": 10,
        "title": "Implement Summary and Commit Message Pop-outs",
        "description": "Build the pop-out UI panels for generating and displaying session summaries and commit messages on demand.",
        "details": "Create `components/chatbot/SummaryPopout.tsx` and `CommitPopout.tsx` using `shadcn/ui`'s `Dialog` or `Sheet` components. Add trigger buttons (e.g., 'Generate Summary') to the main viewer UI. When a button is clicked, the corresponding pop-out should appear and call the `analyzeSessionServerFn` (Task 7) to get the generated content from the backend logic (Task 6). The UI must include a loading state and a 'Copy to Clipboard' button.",
        "testStrategy": "Conduct E2E tests for the entire user flow: click trigger button, assert that the pop-out appears with a loading indicator, wait for the generated text to be displayed, and verify that the copy-to-clipboard action works. Perform accessibility testing on the pop-outs to ensure proper focus management and keyboard navigation.",
        "priority": "medium",
        "dependencies": [
          6,
          7
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Generic Async Pop-out Component",
            "description": "Develop a reusable pop-out component using `shadcn/ui`'s `Dialog` or `Sheet`. This component will manage its own open/closed state and handle the lifecycle of an asynchronous operation, including loading, error, and success states for displaying content.",
            "dependencies": [],
            "details": "Create `components/ui/AsyncContentDialog.tsx`. This component will accept a trigger element, a title, and an async function (`fetchContent`) as props. It will manage loading, error, and data states internally and display a skeleton/spinner while fetching.",
            "status": "pending",
            "testStrategy": "Use Storybook to visually test the component in all its states: default, loading, content displayed, and error. Write unit tests to verify that the `fetchContent` prop is called correctly when the dialog is opened."
          },
          {
            "id": 2,
            "title": "Implement Summary and Commit Message Pop-out Variations",
            "description": "Create the specific `SummaryPopout.tsx` and `CommitPopout.tsx` components. These components will use the generic async pop-out, providing the specific logic and props for fetching session summaries and commit messages by calling the `analyzeSessionServerFn`.",
            "dependencies": [
              1
            ],
            "details": "Create `components/chatbot/SummaryPopout.tsx` and `CommitPopout.tsx`. Each will use the generic `AsyncContentDialog`, passing the appropriate server function to the `fetchContent` prop (e.g., `() => analyzeSessionServerFn({ type: 'summary' })`). Implement the 'Copy to Clipboard' button inside the content area.",
            "status": "pending",
            "testStrategy": "Mock the `analyzeSessionServerFn`. In unit tests or Storybook, verify that each pop-out variant calls the server function with the correct parameters and correctly renders the mocked response. Test the copy-to-clipboard functionality."
          },
          {
            "id": 3,
            "title": "Integrate Pop-out Trigger Buttons into Viewer UI",
            "description": "Add the 'Generate Summary' and 'Generate Commit Message' trigger buttons to the main session viewer UI, wiring them up to launch their respective pop-out components.",
            "dependencies": [
              2
            ],
            "details": "In the main viewer UI, likely near the `ChatDockPanel` (from Task 8), add two new buttons. Integrate the `SummaryPopout` and `CommitPopout` components, using these new buttons as their triggers. Ensure they are correctly positioned and styled.",
            "status": "pending",
            "testStrategy": "Perform an end-to-end manual test in the application. Click each trigger button, verify the corresponding pop-out appears with a loading state, and then displays the generated text. Verify the copy button works and that the UI layout remains correct."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-11-24T22:00:03.220Z",
      "updated": "2025-11-24T22:00:03.220Z",
      "description": "Tasks for master context"
    }
  }
}