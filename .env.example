# Required by env schema
MY_SECRET_VAR=https://example.com

# Enable the dual-mode chatbot stack locally
SESSION_COACH_ENABLED=true

## AI runtime configuration
#AI_OPENAI_COMPATIBLE_API_KEY=your-openai-key
#AI_OPENAI_COMPATIBLE_BASE_URL=http://127.0.0.1:1234/v1
#AI_SESSION_DEFAULT_MODEL=qwen_qwen3-vl-4b-instruct
##AI_GENERAL_DEFAULT_MODEL=openai:gpt-4o-mini
#AI_GENERAL_DEFAULT_MODEL=qwen_qwen3-vl-4b-instruct
#GEMINI_API_KEY=your-gemini-key-if-needed
#GEMINI_AUTH_TYPE=oauth-personal
#GEMINI_CACHE_DIR=
#GEMINI_PROXY=
#GEMINI_SESSION_DIR=/home/user/.gemini
##GEMINI_SESSION_DIR=
# Codex CLI defaults (auth handled by `codex login`)
AI_CODEX_CLI_ALLOW_NPX=true
AI_CODEX_CLI_SKIP_GIT_REPO_CHECK=true
AI_CODEX_CLI_APPROVAL_MODE=on-failure
AI_CODEX_CLI_SANDBOX_MODE=workspace-write
AI_CODEX_CLI_VERBOSE=false
AI_CODEX_CLI_API_KEY=
AI_CODEX_CLI_PATH=

# LM Studio OpenAI-compatible server
AI_LMSTUDIO_BASE_URL=http://127.0.0.1:1234/v1
AI_LMSTUDIO_API_KEY=lm-studio # LM Studio ignores the value but requires a string. Run `lms server start` before selecting LM Studio in the UI.

# Deployment helpers
# When simulating Vercel builds locally, set DEPLOY_TARGET=vercel before running `pnpm run build`.
